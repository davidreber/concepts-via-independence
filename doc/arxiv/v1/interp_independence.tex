\pdfoutput=1
\documentclass{article}


% alptex + small aesthetic tweaks + some extra math defs
\input{preamble/preamble.tex}
\input{preamble/preamble_math}
\input{preamble/definitions_basic}

% bibtex import + some code to strip away useless bib info (volume number, isbn, and the ilk), and to standardize capitalization
% warning: the arxiv uses an outdated bibtex, which causes cryptic and frustrating upload errors 
% easiest solution: install whatever current arxiv texlive is from ftp://tug.org/historic/systems/texlive/ (download the ISO) and compile using this versions pdflatex and bibtex
% alternatively, look upon https://github.com/plk/biblatex/wiki/biblatex-and-the-arXiv and despair. 
\input{preamble/minimalist_biblatex}

\addbibresource{bibs/sensitivity}

\crefformat{equation}{(#2#1#3)}
\crefformat{figure}{Figure~#2#1#3}
\crefname{example}{Example}{Examples}
\crefname{lemma}{Lemma}{Lemmas}
\crefname{cor}{Corollary}{Corollaries}
\crefname{theorem}{Theorem}{Theorems}
\crefname{assumption}{Assumption}{Assumptions}

%********************************************************************
% Extra definitions
%********************************************************************
\usepackage{enumitem} % tight enumerates
\usepackage[separate-uncertainty=true,multi-part-units=single]{siunitx} % better table control

\newcommand{\maxf}[1]{{\cellcolor[gray]{0.8}} #1}
\global\long\def\embedding{\lambda}

% Peter's grey box
\declaretheoremstyle[
%    postheadspace=\newline,
spacebelow=\parsep,
    spaceabove=\parsep,
  mdframed={
    backgroundcolor=gray!10!white,     % vv: weird spacing issue, so leaving transpartent for now
    hidealllines=true, 
    innertopmargin=8pt, 
    innerbottommargin=4pt, 
    skipabove=8pt,
    skipbelow=10pt,
    nobreak=true
}
]{grayboxed}
\declaretheorem[style=grayboxed,name=Assumption]{gassumption}
% \declaretheorem[style=plain]{auxtheorem}
% \declaretheorem[style=grayboxed,sibling=auxtheorem]{algorithm}
% \declaretheorem[style=grayboxed,name=Algorithm]{nalgorithm}
\crefname{gassumption}{Assumption}{Assumptions}

\usepackage{thm-restate}

%********************************************************************
% Dan Roy's commenting code
%********************************************************************
\usepackage{xcolor}
\input{preamble/commenting.tex}
%\input{preamble/myvruler.tex}
%For submission, uncomment these lines to make all annotations render as blank.
% \renewcommand{\LATER}[1]{}
% \renewcommand{\fLATER}[1]{}
% \renewcommand{\TBD}[1]{}
% \renewcommand{\fTBD}[1]{}
% \renewcommand{\PROBLEM}[1]{}
% \renewcommand{\fPROBLEM}[1]{}
% \renewcommand{\NA}[1]{#1}  %% Note, NA's pass through!

% frontmatter
\usepackage[affil-it]{authblk}

\title{Searching for Model Concepts by their Conditional Independencies}
\date{}
\author{TBD}
% \author[1]{David Reber}
% \author[1]{Victor Veitch}
% \author[1,2]{Kaarel HÃ¤nni}
% \affil[1]{Physical Insitute of the Beyond}
% \affil[2]{Ouija Statistical Institute}

\begin{document}
\maketitle

\begin{abstract}
Your abstract here
\end{abstract}

Ongoing attributions:
\begin{itemize}
    \item David: articulating connection to his explainability agenda. Writing first draft.
    \item Kaarel: suggesting the search algorithm
    \item Victor: suggesting obstacles related to rotations
    \item AIs: ChatGPT and Copilot
\end{itemize}

\section{Motivation}
A lot of human understandable concepts have statistical independencies (e.g. because of underlying causal processes). These conditional independencies should help us narrow the search for concepts in a model, in the spirit of the "Discovering Latent Knowledge" paper. [todo: cite]

This research direction is insturmentally valuable to David, because he's focused on context-specific, model-agnostic explainability. But the direction he's going in relies on at least some of the relevant concepts being readable from the model, so if there are easy ways he can help speed that interpretability research, it'll make his particular agenda of explainability more likely to succeed.

\section{Formalizing the problem}
Assume we have three binary concepts $X$, $Y$, and $Z$ which satisfy the conditional independence of $(X\independent Y|Z)$, and we want to find them in a transformer-based generative model. We can do this by searching for a set of three features in the model which satisfy the conditional independence. 

\subsection{What are we searching over?}
Let's assume concepts are represented linearly as subspaces of the embedding space, and the $i^{th}$ layer is simply reasoning over these concepts (but not changing the embedding space itself). If this is true, \textbf{the way that concepts are represented should be consistent in the embedding space across all layers}. 

% \marginpar{An alternative possibility is there is a different embedding space at each layer; that is, that each layer is a transformation from the previous layer's embedding space to a new embedding space. If this is the case, the subspace corresponding to a concept in one layer may not correspond to the same subspace in the next layer. Additionally, if the transformations are not full-rank then we would expect to see concept collapse, where some concepts are not represented in later embedding spaces at all. But this doesn't match Anthropic's results.}

We can think of the overall search as comprising two parts:
\begin{itemize}
    \item Searching over all possible combinations of three subspaces in the embedding space. 
    \item For each combination, checking whether the conditional independence holds. 
\end{itemize}

\subsection{Do we need to worry about rotations?}

Another relevant question is whether there is a privileged basis in the embedding space. If there is, then we can search over the basis vectors. If there isn't, then we need to search over all possible rotations of the embedding space.

\marginpar{cite: https://transformer-circuits.pub/2023/privileged-basis/index.html}
Anthropic's work has provided a bit of evidence that there \textbf{shouldn't be a priveledged basis}. Empirically, there was some evidence that there is anyways, but Anthropic ran some tests and conjecture that it's likely just an artifact of using the Adam optimizer, and not necessary for model performance. So at a first pass, it would seem we need to search over all possible rotations of the embedding space.

If we restrict our search to only the columns of the interaction matrices, what assumptions are we making?
\begin{itemize}
    \item There is a one-to-one correspondence between concepts and columns of the interaction matrices. (In particular, there are no concept-directions which are linear combinations of the columns of the interaction matrices, and \emph{superposition} isn't a thing).
    \item there are no concept-directions corresponding to interactions between layers (read-write operations of later layers building on the read-write operations of earlier layers)
\end{itemize}

I think the superposition point is the biggest reason we're going to need to worry about rotations. If we assume that superposition is a thing, then we can't assume that the columns of the interaction matrices are concept directions.

\subsection{How do we check conditional independencies?}

Regardless of how we enumerate features, we need to be able to check whether the conditional independencies hold. Naively, we could just check whether the conditional independencies hold for a triplet of features. This is doable for discrete features, but challenging for continuous features [todo: verify]. 

It would be nicer if we could specify a loss function which is minimized when the conditional independencies hold. This would allow us to use gradient descent to find the features which satisfy the conditional independencies.

For instance, perhaps we could use a loss function based on KL divergence between the product distribution and the joint distribution on that batch. 

Maybe specifying a continous loss function also allows us to get around the rotation issue, because the rotation is just another set of parameters to do gradient descent over? So long as it doesn't privledge any particular basis?

\subsection{Differentiating relevant concepts}

Any set of three concepts which satisfy the conditional independencies will be a valid solution to the search problem. So for the type of application David is imagining (finding concepts which are relevant to a particular context/task), we need a way to ensure the concepts we find are relevant to the context/task.

Maybe this can be added to the loss function somehow? For instance, maybe we can add a term to the loss function which is minimized when the concepts are relevant to the context/task (aka. supervised probing).

\subsection{Narrowing the search}

Perhaps trying to satisfy several conditional independencies simultaneously helps narrow the search. Maybe searching for 5 concepts with 4 conditional independencies is easier than searching for 3 concepts with 1 conditional independence?

Alternatively, since LLM's seem to be capable of answering questions about the conditional independnece of concepts, maybe we can leverage their own understanding somehow? This would indicate that they have some sort of representation of conditional independencies, which we could use to narrow the search.

\newpage
\appendix{}

\section{April 25 Victor summary}
\begin{itemize}
    \item Assume you have infinite compute and infinite data
    \item It seems like even then you may not be able to do this search easily, because there are infinite rotations you would need to check (there's no privileged basis).
    \item The counterpoint is that LLMs seem to be able to also have an understanding of which concepts are conditionally independent: if you assume that knowledge is also represented somewhere in the model, does that buy you the extra constraints you need to narrow down the search space to something that ever terminates?
\end{itemize}

\section{April 25 discussion with Kaarel}
\begin{itemize}
    \item Transformer model
    \item Causal graph has 3 nodes (actually a CI)
    \item Try all possible variations of 3 places in the residual stream to look at
    \begin{itemize}
        \item Both token position and layer: all possible combinations of places
    \end{itemize}
    \item Look for a feature in each position, testing whether each feature has the independence you want
    \item Should be possible to do using a differentiable loss function
    \begin{itemize}
        \item If binary concepts are sigmoids of affine transformations of features
        \item Then loss depends on whether the CI holds in that batch
        \item KL divergence between product distribution and joint distribution you observe
        \item Need an empirical variant of the mutual information.
    \end{itemize}
    \item Gradient descent is on how to choose 3 positions in the model.
    \item If there are any other concepts which have the same causal structure, this won't be able to differentiate between them
    \begin{itemize}
        \item So we could add a supervised term which matches prompt = "man"
    \end{itemize}
    \item If the 3 variables have deterministic value from a given input, then we could train a supervised probe to match the labels I know to the positions in the model.
\end{itemize}

\end{document}

